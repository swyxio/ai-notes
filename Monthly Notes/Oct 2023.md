


## openai

- Exciting news for @OpenAI devs: we are close to a 1.0 release of the OpenAI Python SDK ðŸŽŠ. You can test the beta version of 1.0 today, we would love to get your early feedback! [changelog](https://twitter.com/StainlessAPI/status/1709650331972379060)

## Models

- Small
	- [ Stable LM 3B: Bringing Sustainable, High-Performance LMs to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices) https://news.ycombinator.com/item?id=37739965
	- Rift coder 7B https://twitter.com/morph_labs/status/1709288051195998375
- ?
	- Reka Yasa-1 Multimodal LLM ([tweet](https://twitter.com/YiTayML/status/1709265184576204820), [blog](https://reka.ai/announcing-our-multimodal-ai-assistant/) - natively supports images, audio, and short video clips as inputs. )
		- Retrieval augmented generation - Yasa can be taught to understand private datasets. Our API and on-premise deployment setup allows seamless integration of internal datasets of any modality type.
		- Code Interpreter - Yasa is more than just a passive AI assistant; it has the capability to actively execute code. This feature is enabled via a simple flag. When active, Yasa automatically identifies the code block within its response, executes the code, and appends the result at the end of the block.Â 

Below is an example of the featureâ€™s ability to perform arithmetic operations, analyze spreadsheets, or create visualizations.

## open source projects and templates


- Daniel Grossâ€™ [LocalPilot](https://x.com/danielgross/status/1708855228122964291?s=20)- â€œIn my experience, 7b isn't usefully fast enough for autocomplete on M1, but M2 Max is the punctuated equilibrium; it's suddenly good enough. (34b quantized models are fast enough for Q&A.)â€œ

## other launches

- Mistral 7B, Llama2 13B, Code Llama 34B, and Llama2 70B models supported [https://blog.perplexity.ai/blog/introducing-pplx-api](https://blog.perplexity.ai/blog/introducing-pplx-api "https://blog.perplexity.ai/blog/introducing-pplx-api")
	- currently included with perplexity pro, no $/token (for now? I'm assuming only in public beta, that won't scale)
	- really leans into openAI api compatibility. They actually just use the openai python client. All you have to do is switch api_base, api_key, and model to point to perplexity to switch an application from openai to perplexity in python
	- (thanks @danjl on Latent Space Discord)

## Papers and Good Reads

- Models
	- [Efficient streaming language models with attention sinks](https://github.com/mit-han-lab/streaming-llm) ([HN](https://news.ycombinator.com/item?id=37740932#37742452))
	- [Expressive text-to-image generation with rich text](https://rich-text-to-image.github.io/) ([HN](https://news.ycombinator.com/item?id=37770260)) - being able to modify generated images by modifying text using fonts and text colors. going from words ->  token maps (masks).
		- [Notable criticism of this method over regular prompting](https://news.ycombinator.com/item?id=37772250)
- Prompting
	- emotional jailbreaks work.Â [https://arxiv.org/abs/2307.11760](https://arxiv.org/abs/2307.11760) "This is very important to my career" and [the dead grandma jailbreak](https://news.ycombinator.com/item?id=37743759)
- RAG
	- [Vector database is not a separate database category](https://nextword.substack.com/p/vector-database-is-not-a-separate) ([HN](https://news.ycombinator.com/item?id=37747534))
	- [ Choosing vector database: a side-by-side comparison](https://benchmark.vectorview.ai/vectordbs.html) ([HN](https://news.ycombinator.com/item?id=37764489))
		- "Everyone I talk to who is building some vector db based thing sooner or later realizes they also care about the features of a full-text search engine.
		- They care about filtering, they care to some degree about direct lexical matches, they care about paging, getting groups / facet counts, etc.
		- Vectors, IMO, are just one feature that a regular search engine should have. IMO currently Vespa does the best job of this, though lately it seems Lucene (Elasticsearch and Opensearch) are really working hard to compete"
	- [Vespa.ai is spinning out of Yahoo as a separate company](https://blog.vespa.ai/vespa-is-becoming-its-own-company/)
- Efficiency
	- [Running Stable Diffusion XL 1.0 in 298MB of RAM](https://github.com/vitoplantamura/OnnxStream/tree/846da873570a737b49154e8f835704264864b0fe)
	- Mistral 7B outperforms Llama 13B on all tested benchmarks -  guide showing how to fine-tune it cost-effectively using QLoRA ([brev tweet](https://twitter.com/HarperSCarroll/status/1709000201963532429))

## Fundraising

- Induced AI $2.3m seed
	- We let anyone create virtual AI workers that can automate the execution of workflows on a browser in the cloud with human-like reasoning.
	- https://twitter.com/aryxnsharma/status/1709289742310010970
- 

## memes

- grandma is the new sudo https://twitter.com/latentspacepod/status/1708982643294146690
- its a rock https://x.com/itsmingjie/status/1709039235913719973?s=46&t=90xQ8sGy63D2OtiaoGJuww