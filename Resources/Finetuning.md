
## openai finetuning resources

- https://platform.openai.com/docs/guides/fine-tuning
- https://cookbook.openai.com/examples/how_to_finetune_chat_models
- https://jsonlint.com/
- https://www.convertjson.com/json-to-jsonlines.htm
- https://jsoning.com/ JSON tools (formatter, validator, JSONPath, JSON Patch, converters)
- related demo projects
	- https://github.com/nub3Ar/Auto-distill-GPT/blob/main/main.py
	- https://github.com/eqian99/finetuning-experiment/blob/main/Benchmark_Latency-Public.ipynb


## llama finetuning

- https://www.anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications
- [Fine-tune your own Llama 2 to replace GPT-3.5/4](https://news.ycombinator.com/item?id=37484135)

Code samples
- https://colab.research.google.com/drive/1mV9sAY4QBKLmS58dpFGHgwCXQKRASR31?usp=sharing#scrollTo=Way3_PuPpIuE
	- https://github.com/mshumer/gpt-llm-trainer

- https://twitter.com/abacaj/status/1729889359040819474?s=12&t=90xQ8sGy63D2OtiaoGJuww
Some guides 
- [https://rentry.org/llm-training](https://t.co/52JRWfpqqV) 
- [https://anyscale.com/blog/fine-tuning-llama-2-a-comprehensive-case-study-for-tailoring-models-to-unique-applications…](https://t.co/t6hSPdS28N) 
- [https://asmirnov.xyz/doppelganger](https://t.co/HFtAg0KgDn) 
- [https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms…](https://t.co/qySkemTaf2)

## datasets

- https://github.com/zhilizju/Awesome-instruction-tuning
- https://huggingface.co/collections/HuggingFaceH4/awesome-sft-datasets-65788b571bf8e371c4e4241a
- https://huggingface.co/collections/HuggingFaceH4/awesome-feedback-datasets-6578d0dc8628ec00e90572eb
